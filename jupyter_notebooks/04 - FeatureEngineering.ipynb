{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD THE NOTEBOOK NAME HERE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your original dataframe\n",
        "df_missing = df.copy()\n",
        "df_missing['BsmtExposure'] = df_missing['BsmtExposure'].fillna('Missing')\n",
        "\n",
        "# One-hot encode BsmtExposure\n",
        "df_encoded = pd.get_dummies(df_missing, columns=['BsmtExposure'], drop_first=True)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# Extract the correlations with SalePrice\n",
        "correlation_with_saleprice = correlation_matrix['SalePrice'].drop('SalePrice')\n",
        "\n",
        "# Plot the correlations with SalePrice\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=correlation_with_saleprice.values, y=correlation_with_saleprice.index, palette=\"viridis\")\n",
        "plt.title('Correlation of BsmtExposure Encoded Variables with SalePrice')\n",
        "plt.xlabel('Correlation coefficient')\n",
        "plt.ylabel('Encoded Variables')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "def correlation_to_sale_price_spearman(df, vars_to_study):\n",
        "    \"\"\" Joint plots of variables vs SalePrice with Spearman correlation annotation \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    \n",
        "    for col in vars_to_study:\n",
        "        # Calculate Spearman correlation\n",
        "        spearman_corr, p_value = spearmanr(df[col], df[target_var])\n",
        "        \n",
        "        # Create scatter plot with regression line\n",
        "        g = sns.lmplot(data=df, x=col, y=target_var, line_kws={'color': 'red'})\n",
        "        \n",
        "        # Set the title and labels\n",
        "        g.set_axis_labels(col, target_var, fontsize=15)\n",
        "        g.fig.suptitle(f\"{col} (Spearman: {spearman_corr:.2f}, p-value: {p_value:.2e})\", fontsize=20, y=1.05)\n",
        "        \n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_to_sale_price_joint(df, vars_to_study):\n",
        "    \"\"\"  Joint plots of variables vs SalePrice \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        x, y, hue = col, target_var, 'OverallQual'\n",
        "        sns.jointplot(data=df, x=x, y=y, kind='hex')\n",
        "        # sns.jointplot(data=df, x=x, y=y, hue=hue)\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.3, x=-3)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "correlation_to_sale_price_joint(df_eda, vars_to_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_to_sale_price_scat(df, vars_to_study):\n",
        "    \"\"\"  scatterplots of variables vs SalePrice \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        fig, axes = plt.subplots(figsize=(8, 5))\n",
        "        axes = sns.scatterplot(data=df, x=col, y=target_var, hue='OverallQual')\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "correlation_to_sale_price_scat(df_eda, vars_to_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_to_sale_price_lm(df, vars_to_study):\n",
        "    \"\"\"  Joint plots of variables vs SalePrice \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        # fig, axes = plt.subplots(figsize=(8, 5))\n",
        "        sns.lmplot(data=df, x=col, y=target_var)\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "correlation_to_sale_price_lm(df_eda, vars_to_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_to_sale_price_hist(df, vars_to_study):\n",
        "    \"\"\" Display correlation plot between variables and sale price \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        fig, axes = plt.subplots(figsize=(8, 5))\n",
        "        axes = sns.histplot(data=df, x=col, y=target_var)\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "correlation_to_sale_price_hist(df_eda, vars_to_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_integer_values_dict = {}\n",
        "\n",
        "for column in df.columns:\n",
        "    # Check if all values in the column are integers\n",
        "    if not df[column].apply(lambda x: isinstance(x, int)).all():\n",
        "        # Collect non-integer values, filtering out floats that don't start with '0.'\n",
        "        non_integer_values = df[column][~df[column].apply(lambda x: isinstance(x, int))]\n",
        "        non_integer_values = non_integer_values[~non_integer_values.apply(lambda x: isinstance(x, float) and not str(x).startswith('0.'))]\n",
        "        # Use a set to ensure uniqueness\n",
        "        unique_non_integer_values = set(non_integer_values)\n",
        "        non_integer_values_dict[column] = list(unique_non_integer_values)\n",
        "\n",
        "# Print the results\n",
        "for column, values in non_integer_values_dict.items():\n",
        "    print(f\"Non-integer values in {column}: {values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch the top scores\n",
        "pps_topscores = pps_matrix.iloc[19].sort_values(key=abs, ascending=False)[1:11]\n",
        "\n",
        "# Print the values\n",
        "print(pps_topscores)\n",
        "\n",
        "# Plot the bar chart\n",
        "plt.bar(x=pps_topscores.index, height=pps_topscores)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Predictive Power Score\", fontsize=20, y=1.05)\n",
        "\n",
        "# Annotate the bars with the values\n",
        "for index, value in enumerate(pps_topscores):\n",
        "    plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your original dataframe\n",
        "df_missing = df.copy()\n",
        "df_missing['BsmtExposure'] = df_missing['BsmtExposure'].fillna('Missing')\n",
        "df_missing['BsmtFinType1'] = df_missing['BsmtFinType1'].fillna('Missing')\n",
        "\n",
        "# Calculate the mean SalePrice for each BsmtExposure category\n",
        "mean_saleprice = df_missing.groupby('BsmtExposure')['SalePrice'].mean().reset_index()\n",
        "\n",
        "# Pivot the dataframe for the heatmap\n",
        "pivot_table = mean_saleprice.pivot(\"BsmtExposure\", \"SalePrice\", \"SalePrice\")\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
        "plt.title('Average Sale Price by BsmtExposure')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr, spearmanr, linregress\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Sample mapping for KitchenQual\n",
        "kitchen_qual_mapping = {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1}\n",
        "\n",
        "# Transform the KitchenQual values to numerical values in the DataFrame\n",
        "df['KitchenQual_num'] = df['KitchenQual'].map(kitchen_qual_mapping)\n",
        "\n",
        "# Display the count of each category in KitchenQual\n",
        "print(df['KitchenQual'].value_counts())\n",
        "\n",
        "# Function to plot a variable against SalePrice with Pearson and Spearman trendlines\n",
        "def plot_with_trendlines(df, vars, target='SalePrice'):\n",
        "    num_vars = len(vars)\n",
        "    plt.figure(figsize=(16, 6 * num_vars))\n",
        "    \n",
        "    for i, var in enumerate(vars, 1):\n",
        "        x = df[var]\n",
        "        y = df[target]\n",
        "        \n",
        "        # Pearson correlation\n",
        "        pearson_coef, _ = pearsonr(x, y)\n",
        "        slope_pearson, intercept_pearson, _, _, _ = linregress(x, y)\n",
        "        line_pearson = slope_pearson * x + intercept_pearson\n",
        "        \n",
        "        # Spearman correlation\n",
        "        spearman_coef, _ = spearmanr(x, y)\n",
        "        lowess_smoothed = lowess(y, x, frac=0.3)\n",
        "        \n",
        "        # Plotting\n",
        "        plt.subplot(num_vars, 1, i)\n",
        "        sns.scatterplot(x=x, y=y, label='Data points')\n",
        "        \n",
        "        plt.plot(x, line_pearson, color='red', label=f'Pearson trendline (r={pearson_coef:.2f})')\n",
        "        plt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='blue', label=f'Spearman trendline (r={spearman_coef:.2f})')\n",
        "        \n",
        "        plt.xlabel(var)\n",
        "        plt.ylabel(target)\n",
        "        plt.title(f'{var} vs {target} with Pearson and Spearman Trendlines')\n",
        "        plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage for multiple variables, including transformed KitchenQual\n",
        "variables = ['YearBuilt', 'OverallQual', 'KitchenQual_num']\n",
        "plot_with_trendlines(df, variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Assuming df is your DataFrame and has been defined elsewhere\n",
        "\n",
        "# Function to plot a variable against SalePrice with Pearson and Spearman trendlines\n",
        "def plot_with_trendlines(df, var, target='SalePrice'):\n",
        "    x = df[var]\n",
        "    y = df[target]\n",
        "    \n",
        "    # Pearson correlation\n",
        "    pearson_coef, _ = pearsonr(x, y)\n",
        "    slope_pearson, intercept_pearson, _, _, _ = linregress(x, y)\n",
        "    line_pearson = slope_pearson * x + intercept_pearson\n",
        "    \n",
        "    # Spearman correlation\n",
        "    spearman_coef, _ = spearmanr(x, y)\n",
        "    lowess_smoothed = lowess(y, x, frac=0.3)\n",
        "    \n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=x, y=y, label='Data points')\n",
        "    \n",
        "    plt.plot(x, line_pearson, color='red', label=f'Pearson trendline (r={pearson_coef:.2f})')\n",
        "    plt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='blue', label=f'Spearman trendline (r={spearman_coef:.2f})')\n",
        "    \n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel(target)\n",
        "    plt.title(f'{var} vs {target} with Pearson and Spearman Trendlines')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example for 'YearBuilt'\n",
        "plot_with_trendlines(df, 'YearBuilt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x='KitchenQual', y='SalePrice', data=df)\n",
        "plt.xlabel('KitchenQual')\n",
        "plt.ylabel('SalePrice')\n",
        "plt.title('SalePrice Distribution by KitchenQual')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='OverallQual', y='SalePrice', data=df)\n",
        "plt.xlabel('OverallQual')\n",
        "plt.ylabel('SalePrice')\n",
        "plt.title('SalePrice Distribution by OverallQual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Ensure plots are displayed in Jupyter notebook\n",
        "%matplotlib inline\n",
        "\n",
        "def correlation_to_sale_price_spearman(df, vars_to_study):\n",
        "    \"\"\" Joint plots of variables vs SalePrice with Spearman correlation annotation \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    \n",
        "    for col in vars_to_study:\n",
        "        # Calculate Spearman correlation\n",
        "        spearman_corr, p_value = spearmanr(df[col], df[target_var])\n",
        "        \n",
        "        # Create scatter plot with regression line\n",
        "        g = sns.lmplot(data=df, x=col, y=target_var, line_kws={'color': 'red'})\n",
        "        \n",
        "        # Set the title and labels\n",
        "        g.set_axis_labels(col, target_var, fontsize=15)\n",
        "        g.fig.suptitle(f\"{col} (Spearman: {spearman_corr:.2f}, p-value: {p_value:.2e})\", fontsize=20, y=1.05)\n",
        "        \n",
        "        plt.show()\n",
        "\n",
        "def plot_categorical_vs_sale_price(df, categorical_vars):\n",
        "    \"\"\" Box plots of categorical variables vs SalePrice with mean curve overlay \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    \n",
        "    for col in categorical_vars:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        \n",
        "        # Create box plot\n",
        "        sns.boxplot(x=df[col], y=df[target_var])\n",
        "        \n",
        "        # Calculate mean SalePrice for each category\n",
        "        means = df.groupby(col)[target_var].mean()\n",
        "        \n",
        "        # Overlay mean SalePrice curve\n",
        "        plt.plot(means.index, means.values, color='red', marker='o', linestyle='--', linewidth=2, markersize=8)\n",
        "        \n",
        "        # Add titles and labels\n",
        "        plt.title(f\"{col} vs {target_var}\", fontsize=20, y=1.05)\n",
        "        plt.xlabel(col, fontsize=15)\n",
        "        plt.ylabel(target_var, fontsize=15)\n",
        "        \n",
        "        plt.xticks(rotation=45)\n",
        "        \n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_eda.head())\n",
        "print(df_eda[vars_to_study].describe())\n",
        "print(df_eda[categorical_vars].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix = df[['KitchenQual_Encoded', 'OverallQual']].corr()\n",
        "print(\"Correlation between KitchenQual and OverallQual:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ppscore as pps\n",
        "\n",
        "# Load the DataFrame with your data\n",
        "df = pd.read_csv(\"/workspace/heritage-housing2/jupyter_notebooks/outputs/datasets/cleaned/HousePricesCleaned.csv\")\n",
        "\n",
        "# Calculate the PPS matrix\n",
        "pps_matrix = pps.matrix(df)\n",
        "\n",
        "# Filter the PPS matrix to show only the rows where 'y' is 'SalePrice'\n",
        "pps_against_saleprice = pps_matrix[pps_matrix['y'] == 'SalePrice']\n",
        "\n",
        "# Sort by the PPS score in descending order\n",
        "pps_against_saleprice_sorted = pps_against_saleprice.sort_values(by='ppscore', ascending=False)\n",
        "\n",
        "# Display the sorted PPS matrix\n",
        "print(pps_against_saleprice_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Identify numeric variables\n",
        "numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Identify categorical variables and convert to numerical\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_vars, drop_first=True)\n",
        "\n",
        "# Update the list of numeric variables to include the new one-hot encoded columns\n",
        "numeric_vars = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure the list of variables is unique\n",
        "numeric_vars = list(set(numeric_vars))\n",
        "\n",
        "# Dictionary to store correlation results\n",
        "correlations = {'Variable': [], 'Pearson': [], 'Spearman': []}\n",
        "\n",
        "# Calculate correlations\n",
        "for var in numeric_vars:\n",
        "    if var != 'SalePrice':  # Exclude the target variable itself\n",
        "        x = df_encoded[var]\n",
        "        y = df_encoded['SalePrice']\n",
        "        \n",
        "        pearson_coef, _ = pearsonr(x, y)\n",
        "        spearman_coef, _ = spearmanr(x, y)\n",
        "        \n",
        "        correlations['Variable'].append(var)\n",
        "        correlations['Pearson'].append(pearson_coef)\n",
        "        correlations['Spearman'].append(spearman_coef)\n",
        "\n",
        "# Create a DataFrame with the correlation results\n",
        "correlation_df = pd.DataFrame(correlations)\n",
        "\n",
        "# Calculate the absolute values of the correlations\n",
        "correlation_df['Abs_Pearson'] = correlation_df['Pearson'].abs()\n",
        "correlation_df['Abs_Spearman'] = correlation_df['Spearman'].abs()\n",
        "\n",
        "# Rank the variables based on absolute correlations\n",
        "correlation_df['Pearson_Rank'] = correlation_df['Abs_Pearson'].rank(ascending=False)\n",
        "correlation_df['Spearman_Rank'] = correlation_df['Abs_Spearman'].rank(ascending=False)\n",
        "\n",
        "# Combine the ranks (average of Pearson and Spearman ranks)\n",
        "correlation_df['Combined_Rank'] = (correlation_df['Pearson_Rank'] + correlation_df['Spearman_Rank']) / 2\n",
        "\n",
        "# Sort the DataFrame based on the combined rank\n",
        "correlation_df.sort_values(by='Combined_Rank', inplace=True)\n",
        "\n",
        "# Display the correlation results\n",
        "print(correlation_df)\n",
        "\n",
        "# Extract the most related variable\n",
        "most_related_variable = correlation_df.iloc[0]['Variable']\n",
        "print(f\"The most related variable to SalePrice is: {most_related_variable}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman,\n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.2, PPS_Threshold = 0.1,\n",
        "                  figsize=(12,10), font_annot = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(x=corr_spearman[:10].index, height=corr_spearman[:10])\n",
        "plt.title(\"Spearman Correlation\", fontsize=20, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.bar(x=corr_pearson[:6].index, height=corr_pearson[:6])\n",
        "plt.title(\"Pearson Correlation\", fontsize=20, y=1.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# The specified variables\n",
        "variables = ['OverallQual', 'GrLivArea', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'YearBuilt']\n",
        "target = 'SalePrice'\n",
        "\n",
        "# Assuming df_corr_pearson and df_corr_spearman are your correlation matrices\n",
        "# Extract the correlation values for the specified variables\n",
        "pearson_values = df_corr_pearson.loc[variables, target]\n",
        "spearman_values = df_corr_spearman.loc[variables, target]\n",
        "\n",
        "# Create a DataFrame to compare the values\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Variable': variables,\n",
        "    'Pearson Correlation': pearson_values.values,\n",
        "    'Spearman Correlation': spearman_values.values\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by 'Pearson Correlation' in descending order\n",
        "sorted_comparison_df = comparison_df.sort_values(by='Pearson Correlation', ascending=False)\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(sorted_comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define your data frame containing these variables and sales price\n",
        "# Assuming `df` is your DataFrame containing the data\n",
        "\n",
        "# Continuous variables\n",
        "continuous_vars = ['YearBuilt', 'BsmtFinSF1', '1stFlrSF', 'OverallQual']\n",
        "\n",
        "# Categorical variables\n",
        "categorical_vars = ['KitchenQual', 'BsmtExposure']\n",
        "\n",
        "# Plot continuous variables against sales price\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i, var in enumerate(continuous_vars, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.scatterplot(x=var, y='SalePrice', data=df)\n",
        "    plt.title(f'{var} vs SalePrice')\n",
        "\n",
        "# Plot categorical variables against sales price\n",
        "for i, var in enumerate(categorical_vars, 1):\n",
        "    plt.subplot(2, 3, len(continuous_vars) + i)\n",
        "    sns.boxplot(x=var, y='SalePrice', data=df)\n",
        "    plt.title(f'{var} vs SalePrice')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### PPS\n",
        "* We notice that 1stFlrSF is dominating while there are five other relevant variables to consider.\n",
        "* We will perform a deeper analysis for the following data:\n",
        "    * OverallQual     0.440962\n",
        "    * KitchenQual     0.261966\n",
        "    * YearBuilt       0.198485\n",
        "    * GarageArea      0.187993\n",
        "    * GarageYrBuilt   0.158649\n",
        "    * YearRemodAdd    0.143284"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pearson correlation\n",
        "* OverallQual       (0.790982)\n",
        "* GrLivArea         (0.708624)\n",
        "* GarageArea        (0.623431)\n",
        "* TotalBsmtSF       (0.613581)\n",
        "* 1stFlrSF          (0.605852)\n",
        "* KitchenQual       (-0.589189)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion of first check for correlation\n",
        "* We want to check if we can use one value in the same category (e.g area or quaility variables) to represent two or more similar to create an effecient variable to use\n",
        "  in pipeline if possible. \n",
        "    * Category - Quality: We have two quality variables Overall Quality and Kitchen Quality we want to see if we have a strong between these ones, we have the following correlation;\n",
        "      * \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* 1stFlrSF - mediate pps but a bit lower on correlation quite close between Pn and Sp.\n",
        "* OverallQual -  lower pps but high correlation with sale price.\n",
        "* BsmtExposure - low pps, and bsmt exposure is not even in the first 6 for pearson and spearman.\n",
        "* YearBuilt - low pps and do not exist in pearson but medium in spearman.\n",
        "* KitchenQual - low pps and negative for pearson, does not exist for spearman.\n",
        "* BsmtFinSF1 - lowest pps does not exists for pearson nor spearman.\n",
        "\n",
        "\n",
        "* BsmtExposure - Only PPS\n",
        "* YearBuilt - PPS and Spearman\n",
        "* KitchenQual - PPS and Pearson\n",
        "* BsmtFinSF1 - Only PPS\n",
        "\n",
        "* GrLivArea - Pearson and Spearman\n",
        "* GarageArea - Pearson and Spearman\n",
        "* TotalBsmtSF - Pearson and Spearman\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spearman correlation\n",
        "* OverallQual     0.809829\n",
        "* GrLivArea       0.731310\n",
        "* YearBuilt       0.652682\n",
        "* GarageArea      0.649379\n",
        "* TotalBsmtSF     0.602725\n",
        "* 1stFlrSF        0.575408"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex;\">\n",
        "    <div style=\"margin-right: 20px;\">\n",
        "        <h2>PPS</h2>\n",
        "        <table>\n",
        "            <tr><th>Variable</th><th>Score</th></tr>\n",
        "            <tr><td>OverallQual</td><td>0.441</td></tr>\n",
        "            <tr><td>KitchenQual</td><td>0.262</td></tr>\n",
        "            <tr><td>YearBuilt</td><td>0.198</td></tr>\n",
        "            <tr><td>GarageArea</td><td>0.188</td></tr>\n",
        "            <tr><td>GarageYrBuilt</td><td>0.159</td></tr>\n",
        "            <tr><td>YearRemodAdd</td><td>0.143</td></tr>\n",
        "        </table>\n",
        "    </div>\n",
        "    <div style=\"margin-right: 20px;\">\n",
        "        <h2>Pearson Correlation</h2>\n",
        "        <table>\n",
        "            <tr><th>Variable</th><th>Correlation</th></tr>\n",
        "            <tr><td>OverallQual</td><td>0.791</td></tr>\n",
        "            <tr><td>GrLivArea</td><td>0.709</td></tr>\n",
        "            <tr><td>GarageArea</td><td>0.623</td></tr>\n",
        "            <tr><td>TotalBsmtSF</td><td>0.614</td></tr>\n",
        "            <tr><td>1stFlrSF</td><td>0.606</td></tr>\n",
        "            <tr><td>KitchenQual</td><td>-0.589</td></tr>\n",
        "        </table>\n",
        "    </div>\n",
        "    <div>\n",
        "        <h2>Spearman Correlation</h2>\n",
        "        <table>\n",
        "            <tr><th>Variable</th><th>Correlation</th></tr>\n",
        "            <tr><td>OverallQual</td><td>0.810</td></tr>\n",
        "            <tr><td>GrLivArea</td><td>0.731</td></tr>\n",
        "            <tr><td>YearBuilt</td><td>0.653</td></tr>\n",
        "            <tr><td>GarageArea</td><td>0.649</td></tr>\n",
        "            <tr><td>TotalBsmtSF</td><td>0.603</td></tr>\n",
        "            <tr><td>1stFlrSF</td><td>0.575</td></tr>\n",
        "        </table>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The most significant variables considering both Pearson and Spearman is: OverallQual, GrLivArea, GarageArea, TotalBsmtSF, 1stFlrSF, YearBuilt (for Pearson correlation the last was KitchenQual but with a lower value hence the YearBuilt was identified as the 6th value)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare pearson and spearman\n",
        "* In this section we will check if there is any significant differences between pearson and spearman for the most significant variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary comparison Pearson, Spearman and Power Predictive Score\n",
        "* If we compare the power predictive score most with the equivavelt for pearson correlation we see the following differences:\n",
        "    * 1stFlrSF PPS (1)  - PC (2) : PPS is calculated at a higher rank than PC.\n",
        "    * OverallQual (2)   - PC (1) : PPS is calculated at a lower rank than PC.\n",
        "    * BsmtExposure (3)  - PC (6) : PPS is calculated at a higher rank than PC.\n",
        "    * YearBuilt (4)     - PC (4) : PPS is calculated at the same rank.\n",
        "    * KitchenQual (5)   - PC (3) : PPS is calculated at a lower rank than PC.\n",
        "    * BsmtFinSF1  (6)   - PC (5) : PPS is calculated at a lower rank than PC.\n",
        "\n",
        "* We noticed that for the pearson and spearman correlation factor, the clearest difference in were the following order: \n",
        "    * YearBuilt     (0.13)\n",
        "    * BsmtFinSF1    (0.09)\n",
        "    * 1stFlrSF      (0.03)\n",
        "    * KitchenQual   (0.02)\n",
        "    * OverallQual   (0.02)\n",
        "    * BsmtExposure  (0.01)  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grade variables according to significance\n",
        "* For the data we are interested to know if the importance of each variable, meaning that values close to either either -1 or 1 are most significant. Sorted by Pearson , furhter analysis on discrepancy between Pearson and Spearman will be done in upcoming sections.\n",
        "1. OverallQual  (Pn.  0.79)\n",
        "2. 1stFlrSF     (Pn.  0.61)\n",
        "3. KitchenQual  (Pn. -0.59)\n",
        "4. YearBuilt    (Pn.  0.52)\n",
        "5. BsmtFinSF1   (Pn.  0.39)\n",
        "6. BsmtExposure (Pn. -0.31)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* OverallQual and KitchenQual\n",
        "    * The quality variables show similarities between the Spearman curves for OverallQual and KitchenQual. For KitchenQual, a poor kitchen quality keeps the price down, resulting in a relatively flat price level between 1.0 and 3.0. However, beyond this point, the price increases significantly with higher quality levels.\n",
        "\n",
        "    * The corresponding curve for OverallQual is closer to the Pearson trendline and indicates a more linear relationship between OverallQual and price. However, the Spearman trendlin e for OverallQual also has a flat appearance for quality levels 1 through 7, after which the price increases more rapidly with each increment in quality, similar to the KitchenQual variable.\n",
        "\n",
        "    * Given these similarities, we believe it is possible to merge the Spearman curves and create a single quality variable for predicting sale price. This approach will be further analyzed in the next notebook, focusing on feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Garage initial assessment\n",
        "Upon initial examination, there is no strong indication that the GarageFinish feature has a significant correlation with the sale price. Additionally, the initial investigation into the relationship between garage area and sale price reveals a relatively low correlation.\n",
        "\n",
        "Given that the size of the house typically exhibits a strong correlation with sale price, the comparatively weaker correlation observed with garage area suggests that other factors may have a more pronounced influence on the final sale price.\n",
        "\n",
        "Further analysis is warranted to understand the nuanced relationship between garage attributes and sale price. This may include exploring potential outliers, considering interactions with other features, and employing more advanced analytical techniques to capture non-linear relationships effectively.\n",
        "\n",
        "By delving deeper into these factors, we can gain a more comprehensive understanding of the garage's impact on property valuation and make more informed decisions regarding its significance in the overall pricing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our analysis of basement exposure, we observed a noteworthy trend: properties with missing values for basement exposure tend to have lower sale prices. This suggests that the absence of basement exposure data may signal certain property characteristics that contribute to decreased market value.\n",
        "\n",
        "Moreover, our examination revealed a subtle but discernible impact on sale price attributed to good living quarters within the basement. Properties featuring well-finished living spaces below ground level exhibited a slight positive influence on sale price, indicating a preference among buyers for quality basement amenities.\n",
        "\n",
        "These findings underscore the importance of considering basement attributes in property valuation, as they can significantly influence market perceptions and ultimately affect sale prices. Further exploration into the nuances of basement features and their impact on property value is warranted to provide deeper insights for real estate decision-making.\n",
        "\n",
        "Since the the sale prices range is lower and closest to \"No\" we will impute the missing values with  \"No\" for future calculations.Section 1 content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is no clear connection between BsmtFinType and sales price. Since low-quality and average recreation rooms are essentially the same, the finish type has little effect. What can be discerned is that the quality of living quarters is influencing the price; however, this is most likely due to location rather than the finish type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sales price tends to increase with newer garages; however, this trend is likely influenced by property characteristics. Outliers were detected between 1993 and 1996, but subsequently, sales prices reverted to lower levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this investigation we can that the following factors are most relevant: Quality, Space(Area), Age(YearBuilt), according to our Business requirement * 1. - \"The client is interested in discovering how the house attributes correlate with the sale price\". We can now know that these factors and the associated variables has the strongest correlation with the sale price. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_kitchen_qualities = df['KitchenQual'].unique()\n",
        "print(\"Unique values in 'KitchenQual' column:\", unique_kitchen_qualities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as they support your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
